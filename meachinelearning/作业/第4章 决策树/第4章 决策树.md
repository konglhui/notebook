## 4.1

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180510/4B93IllA6f.png)

如图p74页 如图4.2所示。决策树使用的是递归中的分而治之策略。递归的返回条件是

（1）当前结点的样本全属于同一类别。（训练误差为0）

（2）单签属性集为空，或是所有样本在所有属性上取值相同，无法划分。（由于不包含冲突数据，所以训练误差为0）

（3）当前结点包含的样本集合为空，不能划分。（训练误差为0）

所以必存在与训练之一致的决策树。

## 4.2

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180510/C9eBAH4djm.png)

最小训练误差会导致决策树过拟合，过拟合就会让测试集的误差过大。

## 4.3

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180510/i0ljF65848.png)







## 4.4

![1525923323873](C:\Users\ADMINI~1\AppData\Local\Temp\1525923323873.png)



## 4.5

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180510/jDKhLKaHLI.png)



## 4.6

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180510/C4HcCiaAki.png)





## 4.7

![1525923360881](C:\Users\ADMINI~1\AppData\Local\Temp\1525923360881.png)





## 4.8

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180510/G0Gbk6CLi3.png)





## 4.9

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180510/Lmi97imH83.png)





## 4.10

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180510/Bhal93fcke.png)





