# 第2章 模型评估与选择

## 2.1 

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180424/Geg9leb85F.png)

$$
= C_{500}^{150}\times C_{500}^{150}
$$

## 2.2

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180424/2j8ckibL2b.png)

**10折交叉验证法：**

- 训练集：90，测试集10（由于是分层抽样，训练集，测试集正反例为平均分配）

- 由于在正反例想等时，训练集为随即猜测，故测试集错误率为50%

**留一法：**

- 训练集：99， 测试集1（正反例数据相等）

- 因为是留一法，故训练集的数据总有一方比另一方多，而且，多的是测试集哪一个数据，故测试集无法分到正确的类，错误率为100%

## 2.3

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180424/6m01cdmKHH.png)

BEP:为P = R

F1 = 为P和R的调和平均，$F1 =  2\times \frac{P\times R}{P+R}$

若F1为P=R时，A的BEP是高于B的。

但若P与R不想等，那么则无法判断，原因如图：有交叉的部分。

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180425/34kfI4FdaG.png)

## 2.4 

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180425/h5A4cJhJJb.png)

混淆矩阵如图：

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180425/KemekJDIK7.png)

查准率$P = \frac{TP}{TP+FP}$在被预测为正例的数据里预测的准确率。

查全率$R = \frac{TP}{TP+FN}$在已知的正例里，正例预测为正例的比例。

真正例率$TPR = \frac{TP}{TP+FN}$在已知的正例里，正例预测为正例的比例。

假正例率$FRP = \frac{FP}{TN+FP}$在已知的反例里，反例预测为反例的比例。

查全率与真正例率是相同的。

查全率、真正例率与假正例率都是代表案例被正确预测的比例。

而查准率是预测结果里的正确率。

## 2.5

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180425/95JDBLh3C3.png)

$IIf((x^{+})<f(x^{-}))$它是所有的正例预测值小于反例，也就是所有预测错的总数。

$\frac{1}{2}IIf((x^{+})=f(x^{-}))$它是所有正例预测值和反例预测值想等，此时我们无法区分正反例时，会随机预测，则它预测错误的总数是想等时总数的一半。

那么：$l_{rank}=\frac{1}{m+m^{-}}\sum_{x_{+}\in D_{+}}\sum_{x_{-}\in D_{-}}(IIf((x^{+})<f(x^{-}))+\frac{1}{2}IIf((x^{+})=f(x^{-})))$

就是错误的总数在所有样本中所占的比例：

而AUC代表的是样本正确预测在样本中所占的比例：

所以：$AUC = 1-l_{rank}$

## 2.6 

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180425/Kce0eIBK6f.png)

错误率可以由分类结果-混淆矩阵计算得出。

而ROC曲线是根据每一个样例在预测时得到的结果而绘制出的曲线图。

ROC曲线y轴的积分是错误率。但是是所有样本被错误分类的比率。

## 2.7

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180425/2Jl6GKbiD9.png)

ROC曲线上点的坐标为（TPR,FPR），那么FNR = 1-TPR，那么代价曲线则为（0，FPR）到（1,FNR）,由所有代价线段构成簇，围取期望总体代价和它的边界–代价曲线，所以人一一条ROC曲线都有一条代价曲线，反之亦然。

## 2.8

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180425/8j6BaADbGk.png)

min-max规范化只于式子中的最大值最小值有关，若其中最大值或最小值是偏差很大的数值，那么产生的$x^{`}$的值的偏差也会非常大。但计算量很小。

而z-score与每个值都有关，所以偏差不会很大，但是他的计算量会非常大。

## 2.9 

![mark](http://p6yio0wew.bkt.clouddn.com/blog/180425/HIGgmI9kH7.png)

(1)提出假设：

$H_{0}:$总体X的分布函数为$F(x)$.

如果总体分布为离散型，则假设具体为

$H_{0}:$总体x的分布率为$P\lbrace X=x_{i} \rbrace=p_{i},i = 1,2,...$

这一步就是把图画出来。

(2)将总体X的取值范围分成k个互不相同的小区见$A_{1},A_{2}.A_{3},...,A_{K}$。

就是将区间分成k份。

(3)把落入第i个小区间的$A_{i}$的样本值的总数记作$f_{i}$，成为组频数（真实值），所有的组频数之和为样本容量n。

(4)当$H_{0}$为真时，根据假设的总体理论分布，可算出总体X的值落入第i个小区间$A_{i}$的概率$p_{i}$，于是，$np_{i}$就是落入第i个小区间$A_{i}$的样本值的理论频数（理论值）。

(5)当$H_{0}$为真时，n次试验中样本值落入第i个小区间$A_{i}$的频率$f_{i}/n$与概率$p_{i}$应很接近，当$H_{0}$不真时，则$f_{i}/n$与概率$p_{i}$应相差很大。基于这种思想，皮尔逊引入检验统计量$\chi ^{2}=\sum_{i =1}^{k}\frac{(f_{i}-np_{i})^{2}}{npi}$,在0假设成的的情况下服从自由度为k-1的卡方分布。

基本原理：卡方检验就是统计样本的时间观测值与理论推断只之间的偏离程度，实际观测值与理论推断值之间的偏离程度就决定卡方值的大小，卡方值越大，越不符合；卡方值越小，偏差越小，越趋于符合，若两个值完全想等时，卡方值就为0，表明理论值完全符合。

来源：[卡方检验-百度百科](https://baike.baidu.com/item/%E5%8D%A1%E6%96%B9%E6%A3%80%E9%AA%8C/2591853?fr=aladdin)

## 2.10

![1524641046654](C:\Users\ADMINI~1\AppData\Local\Temp\1524641046654.png)

不太理解，等着后续如果有所领悟在写。






